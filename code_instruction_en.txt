AI Workflow Orchestrator - System Requirements Specification
1. System Overview and Purpose
This system is a CLI-based automation framework that utilizes the various AI (LLM) model APIs of the OpenRouter platform to automatically process user-defined workflows by concurrently executing, merging, and synthesizing them across multiple AIs.

Its key features are the utilization of real-time web information, inter-AI collaboration and comparison, and a cyclical process of analysis, structuring, and output generation.

2. Functional Specifications and Requirements (Implementation Perspective)
[1] Environment & Setup
Python-based.

Utilizes the OpenRouter API.

The OPENROUTER_API_KEY must be present in an .env file.

Dependency management via Python requirements (.in/.txt).

Must be executable as a standalone CLI application.

[2] Input Files and Configuration
ai_models.txt: A list of OpenRouter model IDs to be used, with one ID per line.

Prompt File (e.g., research.md, writing.md): Describes the task's name and each step in separate sections.

## project name ##: A unique name for the task. Mandatory in the first section.

## prompt1 ##, ## prompt2 ##, …: Step-by-step prompts. The number of steps can be freely added or modified.

Options for reasoning and cross-AI information (collaboration) can be provided per prompt using tags (e.g., # reasoning, # other_ai_info).

All instructions, including system prompts, roles, and output formats, are declaratively defined within this file.

[3] AI Execution and Workflow
For each prompt step, initiate parallel/concurrent API requests to all models listed in ai_models.txt.

The results from each AI are saved in a subfolder based on the task name (e.g., projects/...) as individual response files (p1_MODELNAME.md, final_MODELNAME.md, etc.).

In collaboration steps (other_ai_info), a dynamic prompt is generated for each AI by providing the responses from all other AIs in the following format:

Information-sharing format:
--- RESPONSE FROM [AI Model Nickname] ---
(Full response content from the respective AI)

The "collaboration/cross-reference" feature can be toggled on/off via a command-line flag.

[4] Failure/Exception/Retry Handling
On API request failure: retry 1-2 times with a set interval.

If a specific AI repeatedly fails within the same prompt step, it is considered offline for that step, and the workflow continues without interruption.

[5] Outputs and File Structure
Step-by-step results: projects/TaskName/p1_MODEL.md, p2_MODEL.md, ..., Final: final_MODEL.md.

Real-time progress: Reasoning/response logs are recorded in projects/TaskName/live_logs/MODEL.log.

Task names are automatically sanitized to be valid file/folder names.

[6] Real-time Logging and Progress Display
The CLI provides messages for major workflow progress (e.g., "Starting prompt1...", summary of prompt content, start/completion/failure of each AI response).

The progress of a specific model can be monitored in real-time via a CLI command (e.g., view_log.py).

Utilizes the stream feature of OpenRouter to log the response generation process in real-time.

[7] Project Extensibility and Flexibility
Supports an unlimited number of models and prompt steps.

JSON Validation: In JSON generation steps, the generated output must be self-validated for standard JSON format compliance. If invalid, the AI must recognize the error, correct it, and output the valid format.

3. Technical/Implementation Points
File-based state management: (ai_models.txt, prompt files, .env, projects/…, etc.)

Concurrent processing of AI requests using multi-threading.

System prompts should be defined within each prompt file to assign different roles for different tasks (e.g., "You are a crypto analyst," "You are a novelist").

Detailed error history is recorded in log files.

4. Usage Scenario (Summary)
The user prepares the .env, ai_models.txt, and the desired prompt file.

Runs the command python research_bot.py --prompt [prompt_filename].

All outputs are automatically generated according to the specified workflow.

Live logs can be monitored using view_log.py.

5. Extension Guide
Research Bot: Use research.md prompt file.

Collaborative Novel Writing Bot: Use a novel_writing.md prompt file that assigns different roles.

Code Review Bot: Use a code_review.md prompt file that defines steps for code generation, security review, and refactoring.

By simply defining a new prompt file, any kind of multi-AI collaborative workflow can be created.