CLI 기반 다중 AI 자동화 리서치 봇 - 시스템 요구사항 명세서
1. 시스템 개요와 목적
본 시스템은 OpenRouter 플랫폼의 다양한 AI(LLM) 모델 API를 활용하여, 사용자가 정의한 프로젝트 리서치 프롬프트를 다중 AI에 동시 분산 실행‧병합하면서 자동으로 분석·정리·보고서화하는 CLI 기반 자동화 리서치 봇입니다.

웹 실시간 정보 활용, AI 간 협업/비교, 단계별 분석-구조화-결과물(보고서/요약/트윗 등) 순환이 특징입니다.

2. 기능 명세 및 요구사항 (구현 관점)
[1] 환경/설치 준비
파이썬 기반.

OpenRouter API 활용 — 공식문서 https://openrouter.ai/docs/quickstart 참고.

.env 파일에 OPENROUTER_API_KEY가 반드시 들어 있어야 함.

파이썬 requirements(.in/.txt)로 의존성 관리.

CLI 단독 실행 가능해야 함.

[2] 입력 파일 및 구성
ai_models.txt : 사용할 모델들의 OpenRouter ID를 한 줄씩 작성.

예: gpt-4.1, mistral/mistral-large, openai/gpt-4o, grok-4 등

prompt.md : 프로젝트 기본정보와 각 리서치 단계를 섹션별로 기술.

## project info ## : 조사 프로젝트 소개(이름, 공식웹, 투자자 등). 첫 줄에 프로젝트명 필수.

## prompt1 ##, ## prompt2 ##, … : 단계별 프롬프트. 몇 개든 자유롭게 추가/수정 가능.

프롬프트별로 reasoning 및 교차AI정보(협업) 옵션 제공 가능(주석 또는 태그 활용: # reasoning, # other_ai_info)

섹션 구분, 프롬프트 구조, 출력 포맷 등은 선언적으로 prompt.md 내에서 유연하게 지정.

[3] AI 실행 및 워크플로
각 prompt 단계마다, ai_models.txt에 기재된 모든 모델에 대해 병렬/동시 API 요청.

최초 프롬프트(prompt1)에는 project info + prompt1 텍스트를 AI에 전달.

각 AI의 결과는 프로젝트명 기반 하위폴더(projects/...) 내에, ai별 response 파일(p1_MODELNAME.md, final_MODELNAME.md 등)에 저장.

prompt2 이상은, 각 AI별로 다른 모든 AI의 답변을 적절히 함께 주어(예: “A는 B,C 결과 참고”, “B는 A,C 결과 참고”…), 프롬프트 전체 지시와 함께 본인용 프롬프트를 동적으로 생성하여 전달.

정보 전달 형식: 다른 AI의 결과물을 전달할 때는, 아래와 같이 명확한 마크다운 헤더를 사용하여 각 AI의 출처를 구분해야 함.
--- RESPONSE FROM [AI 모델 별명] ---
(해당 AI의 전체 답변 내용)

“협업/교차참조”(other_ai_info)가 Optional일 경우, 플래그(option)로 온/오프 가능하게.

각 단계별로 동일하게 반복: prompt3, prompt4, ... 마지막까지.

마지막 prompt는 prompt.md 내에서 자동으로 인식.

[4] 실패/예외/재시도
API 요청 실패시(3xx/4xx/5xx, 네트워크, 응답지연 등): 1~2회 일정 시간 간격으로 재시도.

같은 프롬프트 단계 내에서 특정 AI 계속 실패시, 그 AI는 해당 단계에서 오프라인으로 간주하고 워크플로를 중단하지 않고 계속 진행.

[5] 결과물 및 파일구조
각 단계별 결과: projects/프로젝트명/p1_MODEL.md, p2_MODEL.md …, 최종: final_MODEL.md

실시간/진행상황: projects/프로젝트명/live_logs/MODEL.log에 reasoning/답변 로그(스트리밍 반영).

프로젝트명은 파일/폴더명 특수문자 자동변환 처리.

[6] 실시간 로깅/진행상황 표시
CLI에서 워크플로 주요 진행(“prompt1 실행 시작...”, 프롬프트 내용 요약, 각 AI 응답 착수/완료/실패 등)을 메시지로 안내.

각 AI별 답변 및 reasoning을 실시간으로 기록하여, CLI 명령(view_log.py 등)으로 해당 모델 경로의 .log 파일 streaming 확인 가능.

가능한 경우 OpenAI/OpenRouter의 stream 기능을 이용하여 답변 생성 과정을 실시간 반영.

[7] 프로젝트 확장성/유연성
모델 수 무제한 확대 지원(개수 제한 없음).

prompt.md 방식 자유 확장 (섹션명, 단계 수, 포맷, 옵션 등).

출력물 유형(보고서, 요약, 트윗 등)은 prompt.md 내 명령 템플릿으로 자유롭게 정의·변경 가능.

추후 LLM 신기능(웹검색, reasoning 등) 추가 옵션 쉽게 붙일 수 있도록 설계.

JSON 유효성 검증: JSON 생성 단계에서, 생성된 결과물이 표준 JSON 형식을 따르는지 자체적으로 검증해야 함. 만약 유효하지 않은 JSON이 생성될 경우, 오류를 스스로 인지하고 유효한 형식으로 수정하여 다시 출력해야 함.

3. 기술/구현 포인트
파일 기반 상태관리: (ai_models.txt, prompt.md, .env, projects/… 등)

멀티스레드/풀/비동기 등으로 AI 요청 동시처리

실시간 스트리밍 대응 및 장애시 fallback 동작

시스템 프롬프트 통일(각 AI에 시스템 역할 주기: “너는 블록체인 전문 리서처임, 웹검색 필수…”)

각 모델의 친숙한 별명/ID 추출 및 응답 파일 네이밍 일관

에러 발생시, 폴더별 로그에 상세 이력 남김

4. 사용 시나리오(요약)
사용자는 .env, ai_models.txt, prompt.md만 준비해 python research_bot.py 실행.

원하는 단계까지 자동 분석·병합·보고서·요약·트윗 등 모두 생성됨.

실시간 로그는 view_log.py 등으로 프로젝트/모델별로 모니터링 가능.

5. 예시 및 확장 가이드
prompt.md에 ## prompt5 ## 같은 추가 프롬프트 단계 설계 가능.

“교차AI 참조”(other_ai_info)는 프롬프트/실행시 선택적으로 설정.

보고서/요약/트윗 외에도 자유 텍스트, 표, 구조화데이터(JSON), 그래프 등 다양화 가능.

LLM 제공사 모델 최신 목록 탐색은 search_ai_models.py로 지원.